---
title: "Supervised Learning for Classification Problems"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(rpart) #basic tree library (can look up the vignette to review all the underlying math in this library... cool!)
library(rpart.plot)
library(ipred) #bagging library
library(randomForest) #random foreset library
library(ada) #boosting for classification library
#can also use xgboost (most complicated and difficult to train, not used here but can use in cases where ada proves insufficient), also have a library called adabag that might be of interest
#May also want to look into caret package (has an accompanying book called Predictive Modeling), very robust and pulls in a lot of the tree models for you along with extra functions that do useful things with trees
library(adabag) #for boosting when predicting factors with more than 2 levels
library(mosaic)

#Package in R for future use: XGBOOST. Constructs boosted trees. Not in today's example but has many options for tweaking and improving performance. 

#Brant's function for building a misclassification table and printing the missclassification rate
misclass = function(fit,y) {
temp <- table(fit,y)
cat("Table of Misclassification\n")
cat("(row = predicted, col = actual)\n")
print(temp)
cat("\n\n")
numcor <- sum(diag(temp))
numinc <- length(y) - numcor
mcr <- numinc/length(y)
cat(paste("Misclassification Rate = ",format(mcr,digits=3)))
cat("\n")
}
```


#LOOKING AT DATA ON BREAST CANCER DIAGNOSIS VIA FINE NEEDLE ASPIRATION
```{r, fig.height=9,fig.width=9}
#Loading data from the BreastDiag.csv file
BreastDiag <- read.csv(file.choose(), header =TRUE)

#Making a train and a test set (in the real world, we'd want to split 3x: train, test, and validation sets)
samp <- sample(1:569, floor(569*.666667), replace = FALSE)

BCtrain <- BreastDiag[samp,]
BCtest <- BreastDiag[-samp,]

#Making a tree and plotting it
bc.rpart <- rpart(Diagnosis~., data = BCtrain)
prp(bc.rpart)

#Checking the fit
yfit <- predict(bc.rpart,type="class")
misclass(yfit, BCtrain$Diagnosis)

#How was this model constructed?
summary(bc.rpart)

#Fine tuning the model 
bc.rpart2 <- rpart(Diagnosis~.,data=BCtrain,cp=0.0001,minsplit=4)
yfit <- predict(bc.rpart2,type="class")
misclass(yfit,BCtrain$Diagnosis)
#With a misclassification rate of 0, did we overfit?

#plotting bc.rpart2
prp(bc.rpart2, type=4,extra=3,cex=0.7)

#Comparing the predictive power of both models
#Model 1
ypred = predict(bc.rpart,newdata=BCtest,type="class")
misclass(ypred,BCtest$Diagnosis)
#Model 2
ypred = predict(bc.rpart2,newdata=BCtest,type="class")
misclass(ypred,BCtest$Diagnosis)
#Notice that model 2 is not as good for predicting as model 1. This is the result of overfitting to the training data.
```

#LOOKING AT A BREAST CANCER MODEL MADE WITH BAGGING
```{r}
bc.bag <- bagging(Diagnosis~.,data=BCtrain, nbagg=100,control=rpart.control(cp=0.019,minsplit=5,xval=0),coob=TRUE)
bc.bag

#Using bc.bag to predict 
ypred <- predict(bc.bag,newdata=BCtest, type = "class")
misclass(ypred,BCtest$Diagnosis)
```
#LOOKING AT A RANDOM FOREST MODEL FOR BREAST CANCER
```{r}
bc.rf <- randomForest(Diagnosis~.,data=BCtrain)
bc.rf

#plotting important variables in the forest
varImpPlot(bc.rf)

#using bc.rf to predict
ypred <- predict(bc.rf,newdata = BCtest,type="class")
misclass(ypred,BCtest$Diagnosis)
#Best misclassification rate so far
```

#USING BOOSTING TO IMPROVE MISCLASSIFICATION RATE BY WEIGHTING ON THE MISCLASSIFIED CASES

A special note about boosting: when only weak classifiers are available, boosting is one of the best available methods to build a strong classification model. Boosting is built on a lot of weak classifiers that collectively become a strong classification system.

```{r}
set.seed(123)
bc.boost <- ada(Diagnosis~.,data=BCtrain)
bc.boost
summary(bc.boost)

#checking the misclassification rate
ypred <- predict(bc.boost,newdata=BCtest)
misclass(ypred,BCtest$Diagnosis)
#Notice that, without any adjustments, bc.boost competes with the random forest model. Brant's model (out of the box, due to the randomness of the data) had a lower misclassification rate than the random forest. With some adjusting, boosting is very likely to perform the best out of the options listed here.
```

#LOOKING AT GROWING REGIONS FOR OLIVE OIL
```{r}
#Loading data from OliveOils.csv
oils <- read.csv(file.choose(),header = TRUE)

#Making a training and a testing set
train <- sample(1:572, floor(.666667*572),replace = FALSE)
oil.train <- oils[train,]
oil.test <- oils[-train,]

#fitting a single tree
oil.rpart <- rpart(Area.name~.,data=oil.train, cp = 0.00001, minsplit = 2)

#Checking misclassification
ypred2 <- predict(oil.rpart,newdata=oil.test, type = "class")
misclass(ypred2,oil.test$Area.name) #misclass rate = 0.157

#Using bagging to improve the simple tree
oil.bag <-bagging(Area.name~.,data=oil.train, nbagg = 750, control = rpart.control(cp=0.0001,minsplit=2,xval=0), coob=TRUE)

ypred3 <- predict(oil.bag,newdata=oil.test, type = "class")
misclass(ypred3,oil.test$Area.name) #misclass rate = 0.0942

#growing a random forest
oil.rf <- randomForest(Area.name~.,data=oil.train)

ypred4 <- predict(oil.rf,newdata=oil.test, type = "class")
misclass(ypred4,oil.test$Area.name) #misclass rate = 0.0576

#trying boosting
oil.boost <- boosting(Area.name~.,data=oil.train,mfinal=100,control=rpart.control(cp=0.0001,minsplit=2))

ypred5 <- predict(oil.boost,newdata=oil.test, type = "class")
misclass(ypred5$class,oil.test$Area.name) #misclass rate = 0.0681
```

#PREDICTING THE EDIBILITY OF MUSHROOMS
```{r}
#loading Mushrooms.csv
mushrooms <- read.csv(file.choose(), header = TRUE)

#taking out columns with zero variance
mush <- mushrooms[,-c(12,17)]

#making test and train sets
train <- sample(1:nrow(mush),floor(nrow(mush)*0.5),replace=FALSE)
mush.train <- mush[train,]
mush.test <- mush[-train,]

#making a tree
mush.tree <- rpart(Poisonous~.,data=mush.train,control = rpart.control(minbucket=0, cp =0.00001))
summary(mush.tree)
prp(mush.tree)

ypred <- predict(mush.tree,data=mush.test,type="class")
misclass(mush.test$Poisonous,ypred)
```

